import torch
from torch import nn
import numpy as np
import torch.utils.data as Data
from torch.nn import init
import torch.optim as optim
from collections import OrderedDict
import LogisticNet
from matplotlib import pyplot as plt


plt.legend(['InitialData','ResultData'])
num_inputs = 2
num_examples=1000
true_w=[2,-3.4]  #çœŸå®žæƒé‡
true_b=4.2  #åå·®
features=torch.tensor(np.random.normal(0,1,(num_examples,num_inputs)),dtype=torch.float)
labels=true_w[0]*features[:,0]+true_w[1]*features[:,1]+true_b
labels = labels.exp() / (labels.exp() + 1)
labels+=torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float)

def initialData(labels):
    for i in range(0,labels.shape[0]):
        if(labels[i]>0.5):
            labels[i]=1
        else:
            labels[i]=0
initialData(labels)

#è¯»å–æ•°æ®
lr = 0.03
batch_size = 10
dataset = Data.TensorDataset(features, labels)
data_iter = Data.DataLoader(
    dataset=dataset,      # torch TensorDataset format
    batch_size=batch_size,      # mini batch size
    shuffle=True,               # æ˜¯å¦æ‰“ä¹±æ•°æ® (è®­ç»ƒé›†ä¸€èˆ¬éœ€è¦è¿›è¡Œæ‰“ä¹±)
    num_workers=0,              # å¤šçº¿ç¨‹æ¥è¯»æ•°æ®ï¼Œæ³¨æ„åœ¨Windowsä¸‹éœ€è¦è®¾ç½®ä¸º0)
)
print(dataset)
#å°†åˆå§‹çš„æ•°æ®æ‰“å°å‡ºæ¥
plt.scatter(features[:,1].numpy(),labels.numpy(),label='InitialData')
#plt.show()

num_outputs=1
#net =LogisticNet.LogisticNet()


net = nn.Sequential(
    OrderedDict([
        ('linear', nn.Linear(num_inputs, 1)),
        ('sigmoid', nn.Sigmoid())
    ])
)

#å‚æ•°åˆå§‹åŒ–
init.normal_(net[0].weight, mean=0, std=0.01)
init.constant_(net[0].bias, val=0)   #ä¹Ÿå¯ä»¥ç›´æŽ¥ä¿®æ”¹biasçš„data
loss = nn.MSELoss()
#å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•
learningRate = 0.005
optimizer = optim.SGD(net.parameters(), lr=learningRate)  #æ¢¯åº¦ä¸‹é™çš„å­¦ä¹ çŽ‡æŒ‡å®šä¸º0.03
num_epochs = 30

#å‡†ç¡®çŽ‡è®¡ç®—å‡½æ•°
def accuracy(y_hat, y):
    return (y_hat.argmax(dim=1) == y).float().mean().item()

#è¯„ä»·æ¨¡åž‹ ð§ðžð­åœ¨æ•°æ®é›† ððšð­ðš_ð¢ð­ðžð« ä¸Šçš„å‡†ç¡®çŽ‡

def evaluate_accuracy(data_iter, net):
    acc_sum, n = 0.0, 0
    for X, y in data_iter:
        acc_sum += (net(X).argmax(dim=1) == y).float().sum().item()
        n += y.shape[0]
    return acc_sum / n

for epoch in range(1, num_epochs + 1):
    for X, y in data_iter:
        output = net(X)
        l = loss(output, y.view(-1, 1))
        optimizer.zero_grad()
        l.backward()
        optimizer.step()
    print('epoch %d, loss: %f' % (epoch, l.item()))

print(true_w, '\n', net[0].weight)
print(true_b, '\n', net[0].bias)


#å‡†ç¡®çŽ‡
def accuracy(y_hat, y):
    for i in range(0, y_hat.shape[0]):
        if (y_hat[i][0] > 0.5):
            y_hat[i][0] = 1
        else:
            y_hat[i][0] = 0
  #  return (y_hat.argmax(dim=1) == y).float().mean().item()
    return (y_hat == y).float().mean().item()


def evaluate_accuracy(data_iter, net,w,b):
    acc_sum, n = 0.0, 0
    for X, y in data_iter:
        acc_sum += (net(X,w,b).argmax(dim=1) == y).float().sum().item()
        n += y.shape[0]
        return acc_sum / n

labels_true=net[0].weight.T[0]*features[:,0]+net[0].weight.T[1]*features[:,1]+net[0].bias
labels_true = labels_true.exp() / (labels_true.exp() + 1)
labels_true+=torch.tensor(np.random.normal(0,0.01,size=labels.size()),dtype=torch.float)
initialData(labels_true)
plt.scatter(features[:,1].numpy(),labels_true.detach().numpy(),color = 'r',label='ResultData')
plt.legend()
plt.show()
